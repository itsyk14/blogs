{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "#mnist contains images dataset with each image dataset labelled from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set shape is : \n",
      "(55000, 784) (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training-set shape is : \")\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set shape is : \n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set shape is : \")\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting first image in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e324826ec8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plotting the first image in dataset to get a idea how our dataset looks like\n",
    "first_image = mnist.train.images[0]\n",
    "first_image=first_image.reshape(28,28)\n",
    "plt.imshow(first_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Convolution Layer(32 units), Filter shape:(5,5,1), Stride=1, Padding='SAME'\n",
    "    Max pooling Layer, Window shape:(2,2), Stride=1, Padding='SAME'\n",
    "    Convolution Layer(64 units), Filter shape:(5,5,32), Stride=1, Padding='SAME'\n",
    "    Max pooling Layer, Window shape:(2,2), Stride=1, Padding='SAME'\n",
    "    Dense Layer (1024 units)\n",
    "    Output Layer (10 units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing our constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input \n",
    "input_pixels = 784\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "\n",
    "#1st convolution layer\n",
    "n_conv1 = 32\n",
    "stride_conv1 = 1\n",
    "padding_conv1=\"SAME\"\n",
    "filter_conv1_k = 5\n",
    "\n",
    "#Pooling Layer1\n",
    "max_pool1_k = 2\n",
    "padding_pool1=\"SAME\"\n",
    "\n",
    "\n",
    "#2nd convolution layer\n",
    "n_conv2 = 64\n",
    "stride_conv2 = 1\n",
    "padding_conv2=\"SAME\"\n",
    "filter_conv2_k = 5\n",
    "\n",
    "#Pooling Layer2\n",
    "max_pool2_k = 2\n",
    "padding_pool2=\"SAME\"\n",
    "\n",
    "#dense layer\n",
    "n_hidden = 1024\n",
    "\n",
    "#output layer\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### before we proceed we need to find the shape of input coming to hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_width=input_width//(max_pool1_k*max_pool2_k)\n",
    "hidden_height=input_height//(max_pool1_k*max_pool2_k)\n",
    "hidden_channels=n_conv2\n",
    "\n",
    "input_hidden =hidden_width*hidden_height*hidden_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing our weights and bias with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"weights_CL1\" : tf.Variable(tf.random_normal([filter_conv1_k,filter_conv1_k, input_channels, n_conv1])),\n",
    "    \"weights_CL2\" : tf.Variable(tf.random_normal([filter_conv2_k, filter_conv2_k, n_conv1, n_conv2])),\n",
    "    \"weights_hidden_layer\" : tf.Variable(tf.random_normal([input_hidden, n_hidden])),\n",
    "    \"weights_output\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bias_CL1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bias_CL2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bias_hidden_layer\" : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bias_output\" : tf.Variable(tf.random_normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    no weights are required for pooling layer\n",
    "    number of wts for 1st covolutional layer is: filter(5x5) X input_channels x no of    units in layer\n",
    "    similarly for 2nd convolutional layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions for creating Convolution Layer and Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, weights, bias, strides = 1,padding=\"VALID\"):\n",
    "    #creating a convolution layer\n",
    "    out = tf.nn.conv2d(x, weights, padding=padding, strides = [1, strides, strides, 1])\n",
    "    #adding bias\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    #applying activation function,you can change activation func from relu to a different one if you want\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def maxpooling(x, k = 2,padding=\"VALID\"):\n",
    "    return tf.nn.max_pool(x, padding = padding, ksize = [1, k, k, 1], strides = [1, k, k, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x, weights, biases):\n",
    "    \n",
    "    #reshaping x into format of \n",
    "    x = tf.reshape(x, shape = [-1 ,input_height, input_width, input_channels])\n",
    "    \n",
    "    conv1 = conv(x, weights['weights_CL1'], biases['bias_CL1'], stride_conv1,padding_conv1)\n",
    "    pool1 = maxpooling(conv1, max_pool1_k,padding_pool1)\n",
    "    \n",
    "    \n",
    "    conv2 = conv(pool1, weights['weights_CL2'], biases['bias_CL2'],stride_conv2,padding_conv2)\n",
    "    pool2 = maxpooling(conv2, max_pool2_k,padding_pool2)\n",
    "    \n",
    "    \n",
    "    hidden_input = tf.reshape(pool2, shape = [-1, input_hidden])\n",
    "    a=tf.add(tf.matmul(hidden_input, weights['weights_hidden_layer']), biases['bias_hidden_layer'])\n",
    "    hidden_output = tf.nn.relu(a)\n",
    "    \n",
    "    \n",
    "    #for output layer we're applying activation function\n",
    "    output = tf.add(tf.matmul(hidden_output, weights['weights_output']), biases['bias_output'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating placeholders for x, y and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "pred = cnn(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our Cost function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling session to start running our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 cost is : 348.6542\n",
      "Epoch 2 cost is : 126.46548\n",
      "Epoch 3 cost is : 122.805244\n",
      "Epoch 4 cost is : 41.34507\n",
      "Epoch 5 cost is : 27.618818\n",
      "Epoch 6 cost is : 19.282413\n",
      "Epoch 7 cost is : 9.250713\n",
      "Epoch 8 cost is : 7.128848\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "for i in range(8):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "    \n",
    "    print(\"Epoch \"+str(i+1)+\" cost is :\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 96.73\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "\n",
    "print(\"Accuracy is :\", (correct_preds.sum()/mnist.test.images.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
